# SKN07-3rd-3Team

# ğŸ“˜ RAG-based English Learning Chatbot
 
## ğŸ‘¥ Team Introduction
| <img src="https://github.com/user-attachments/assets/b5a17c3c-8415-409b-ae90-0a931e677fc3" width="250" height="250"/> | <img src="https://github.com/user-attachments/assets/005f1a53-0700-420e-8c62-ae1555dd538b" width="250" height="260"/> | <img src="https://github.com/user-attachments/assets/3009a31a-d5ab-469a-bf39-39e6c7779efe" width="250" height="250"/>  | 
|:----------:|:----------:|:----------:|
| English Teacher | Korean Teacher | Social Studies Teacher | 
| Joohyeok Seo | Sungwon Dae | Jungyeon Yoon | 

<br>

---

## ğŸ“– Project Overview
- Project Name: RAG-based English Learning Chatbot
- Project Description: The AI High School Equivalency Exam (GED) Learning Tutor is a service designed to assist learners preparing for the GED exam. It is based on seven years of past GED exam questions, from 2018 to 2024. Users can input their questions, and the AI provides correct answers along with explanations.
  This project utilizes Retrieval-Augmented Generation (RAG) technology to facilitate English learning through a Streamlit-based chatbot. Users can either ask general questions or solve randomly generated questions from the FAISS database.
  
- Project Necessity (Background):
  - Traditional GED study materials lack an interactive system that provides instant responses to individual questions.
  - Since this system is designed based solely on past exam questions, learners can systematically and efficiently prepare for the GED exam.
  - The project aims to provide a public learning opportunity for students facing economic or environmental challenges that make formal education difficult, contributing to reducing the education gap.

- Project Objectives:
  This project aims to help learners prepare for the GED exam more effectively using AI technology.
  - Develop a Q&A Service: Utilize ChatGPT API to generate AI-based responses to user queries, based on GED exam questions from 2018 to 2024.
  - Implement NLP and LLM (ChatGPT API): Apply text analysis and document comprehension techniques to improve the accuracy of responses.
  - Provide a User-Friendly Interface: Design an intuitive and accessible learning environment for students.
  - Enhance Learning Efficiency: Offer a real-time AI-powered response system to facilitate effective learning.
  - Deliver Personalized Learning: Analyze the user's weak areas and provide targeted questions, answers, and explanations to support their learning progress.

---

## ğŸš€ Key Features

1. **General Question Response**
   - Generates responses using OpenAI GPT-3.5 based on user-input questions.
2. **Random Quiz Mode**
   - Retrieves random English questions from the FAISS database, allowing users to practice.
   - Provides multiple-choice options and allows users to check the correct answer.

---

## ğŸ“‚ Project Structure

<img src="https://github.com/user-attachments/assets/81339928-6c06-4bf1-8871-71630856ecac" alt="Project Structure" width="800px">

---

## ğŸ”§ Technology Stack
<p align="center">
  <img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/git-F05032?style=flat-square&logo=git&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/python-3776AB?style=flat-square&logo=python&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/streamlit-FF4B4B?style=flat-square&logo=streamlit&logoColor=white" width="150" height="45" />
</p>
<br>
<p align="center">
  <img src="https://img.shields.io/badge/jupyter-F37626?style=flat-square&logo=jupyter&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/openai-412991?style=flat-square&logo=openai&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/discord-5865F2?style=flat-square&logo=discord&logoColor=white" width="150" height="45" />
</p>



---

## ğŸ“‘ Main Procedures

### â–¶ï¸ 1. Data Collection â€“ Web Crawling (Korea Institute for Curriculum and Evaluation, KICE)
- Extracting Code Numbers for Each Year, Education Level, Session, and Subject from the Main Page
```python
code_dict = {}
tmp = 1
while True:   # Retrieve All Page Information
    url = f'https://www.kice.re.kr/boardCnts/list.do?type=default&page={tmp}&selLimitYearYn=Y&selStartYear=2018&C06=&boardID=1500211&C05=&C04=&C03=&searchType=S&C02=&C01='
    re = requests.get(url)
    soup = BeautifulSoup(re.text, 'html.parser')
    
    if soup.find('td').text.strip() == 'No Registered Posts Available.':
        break
        
    info = soup.find('tbody').find_all('tr')
    
    for i in info:
        code = i.find_all('td')[0].text
        year = i.find_all('td')[1].text
        edu = i.find_all('td')[2].text
        cnt = i.find_all('td')[3].text
        subject = i.find_all('td')[4].find('a')['title']
        # Select Desired Data Information
        if edu == 'High School Equivalency Level' and subject == 'English':
            code_dict[code] = f'{year}_{edu}_{cnt}_{subject}'
    
    tmp += 1
```
![image](https://github.com/user-attachments/assets/be19cd7c-60ca-4ed9-a431-04b07a2ace09)
- Access Detailed Pages Using Extracted Code Numbers and Save PDF Files
```python
for code in code_dict.keys():
    down_url = f'https://www.kice.re.kr/boardCnts/view.do?boardID=1500211&boardSeq={code}&lev=0&m=030305&searchType=S&statusYN=W&page=1&s=kice'
    down_re = requests.get(down_url)
    down_soup = BeautifulSoup(down_re.text)
    tmp_url = down_soup.find(class_='fieldBox').find('a')['href']
    pdf_url = 'https://www.kice.re.kr' + tmp_url
    file_path = f'./data/Correct Answers/{code_dict[code]}.pdf'
    
    response = requests.get(pdf_url)
    # Save Files Only When the Response Status Code is 200 (Success)
    if response.status_code == 200:
        with open(file_path, 'wb') as file:
            file.write(response.content)  # Save PDF Files
```

</br>

### â–¶ï¸ 2. Data Extraction
### 2-1) Extract High School English Questions

- Extract Questions from PDF and Arrange Left/Right Columns in the Correct Order
```python
def extract_text_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        combined_text_list = []

        for page in pdf.pages:
            width, height = page.width, page.height

            # Left Column Questions (Process Left Side First for Each Page)
            left_bbox = (0, 0, width / 2, height)
            left_crop = page.within_bbox(left_bbox)
            left_text = left_crop.extract_text()
            if left_text:
                combined_text_list.append(clean_text(left_text))  # Organize and Append Data

            # Right Column Questions (Process Right Side After Each Page)
            right_bbox = (width / 2, 0, width, height)
            right_crop = page.within_bbox(right_bbox)
            right_text = right_crop.extract_text()
            if right_text:
                combined_text_list.append(clean_text(right_text))
```

- OCR Processing for Image-based PDFs (Left to Right per Page)
```python
def extract_text_from_image_pdf(pdf_path):
    images = convert_from_path(pdf_path, dpi=300)
    combined_text_list = []

    for img in images:
        width, height = img.size

        # Left Column Question OCR
        left_crop = img.crop((0, 0, width // 2, height))
        left_text = pytesseract.image_to_string(left_crop, lang="eng+kor", config="--psm 6")
        combined_text_list.append(clean_text(left_text))

        # Right Column Question OCR
        right_crop = img.crop((width // 2, 0, width, height))
        right_text = pytesseract.image_to_string(right_crop, lang="eng+kor", config="--psm 6")
        combined_text_list.append(clean_text(right_text))

    return "\n".join(combined_text_list)
```

### 2-2) Extract High School English Answers
- Extract English Answers from PDF (Including OCR Processing)
```python
def extract_english_answers_from_pdf(pdf_path):
    answers = {}

    # 1ï¸âƒ£ Extract Text Directly from PDF
    with pdfplumber.open(pdf_path) as pdf:
        text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])

    # 2ï¸âƒ£ Apply OCR (Use OCR if Text is Empty)
    if not text.strip():
        text = extract_text_from_image_pdf(pdf_path)

    # 3ï¸âƒ£ Output Raw Text Extracted via OCR (For Debugging Purposes)
    print("\nğŸ“ OCR EXTRACTED TEXT FROM PDF:", pdf_path)
    print(text[:1000])  # Output First 1,000 Characters Only

    # 4ï¸âƒ£ Find Sections Containing "English Answer Table" or "Session 3: English"
    match = re.search(r"(?:English Answer Table|Session 3: English|English)([\s\S]+?)(?=\n\w+ Answer Table|\Z)", text)
    if match:
        english_answers_section = match.group(1).strip()
    else:
        print(f"âš  English Answers Not Found: {pdf_path}")
        return None

    # 5ï¸âƒ£ Extract Answer Patterns (Include Debugging Output)
    extracted_text = convert_korean_numbers(english_answers_section)
    print("\nğŸ” EXTRACTED ENGLISH ANSWERS SECTION:")
    print(extracted_text[:500])  # Output First 500 Characters Only

    # 6ï¸âƒ£ Extract Question Numbers & Answers
    answer_pattern = re.findall(r"(\d+)\s+([â‘ â‘¡â‘¢â‘£1-4])", extracted_text)

    # ğŸ”¥ Debugging: Output Extracted Answers
    print("\nğŸ” Extracted Answers Dictionary:", answer_pattern)

    for q_num, ans in answer_pattern:
        answers[q_num] = ans

    return answers
```

### 2-3) Merge High School English Questions and Answers into a JSON File
- Rename Files to Match Question and Answer Filenames
```python
def clean_filename(filename):
    return filename.replace("_High_School_Answers.pdf", "_High_School_English.pdf")  # Match Answer Filenames with Question Filenames
```

- Modify Key Values in the Converted Answer Data
```python
answers_data_fixed = {clean_filename(k): v for k, v in answers_data.items()}\
```

- Match Questions with Answers
```python
merged_data = {}

for file_name, question_content in questions_data.items():
    matched_file = clean_filename(file_name)
    if matched_file in answers_data_fixed:  # Add Only If an Answer Exists
        merged_data[file_name] = {
            "questions": question_content,
            "answers": answers_data_fixed[matched_file]
        }
    else:
        print(f"âš  Question Files Without Answers: {file_name}")
```

</br>

### â–¶ï¸ 3. Embedding
- OpenAIì˜ "text-embedding-ada-002" Convert Questions into Vectors Using a Model
```python
def get_embedding(text):
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding  # Apply the Latest API Method

# Convert All Questions into Embeddings
question_embeddings = [get_embedding(q) for q in questions]
```

- Create FAISS Database
```python
embedding_dim = 1536  # Set Vector Dimensions
index = faiss.IndexFlatL2(embedding_dim)  # Create FAISS Index
question_vectors = np.array(question_embeddings).astype("float32")  # Convert Embedding Data to NumPy Array
index.add(question_vectors)  # FAISS ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
```

- Search for Similar Questions Using FAISS
```python
def search_similar_questions(query, top_k=3):
    # Convert Input Question into a Vector
    query_vector = np.array(get_embedding(query)).astype("float32").reshape(1, -1)

    # Search for the Closest Question
    distances, indices = index.search(query_vector, top_k)

    # Display Results
    print("\n[Most Similar Questions]")
    for i in range(top_k):
        idx = indices[0][i]
        print(f"{i+1}. {questions[idx]} (ê±°ë¦¬: {distances[0][i]:.4f})")
```

- Save FAISS Index
```python
faiss.write_index(index, "faiss_index.bin")
```

</br>

### â–¶ï¸ 4. Improve Performance with RAG (Retrieval-Augmented Generation)
- OpenAI Embedding
```python
client = openai.OpenAI()

# Embedding Conversion Function
def get_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding  # Apply Latest API Method
```
- Search for Similar Questions in FAISS
```python
def search_similar_questions(query, top_k=3):
    query_vector = np.array(get_embedding(query)).astype("float32").reshape(1, -1)
    distances, indices = index.search(query_vector, top_k)

    # Generate List of Similar Questions
    similar_questions = [questions[idx] for idx in indices[0]]

    print("\n[Most Similar Questions]")
    for i, question in enumerate(similar_questions):
        print(f"{i+1}. {question} (Similarity Distance: {distances[0][i]:.4f})")

    return similar_questions
```
- Connect to GPT-4 for Final RAG Response Generation
```python
def generate_response(query):
    similar_questions = search_similar_questions(query, top_k=3)     # Find Similar Questions
    context = "\n".join(similar_questions)     # Use Retrieved Questions as Prompt Context

    # Setting up GPT-4 Prompt
    prompt = f"""
    You are an AI assistant. Use the following context to answer the question.

    Context:
    {context}

    Question: {query}

    Answer:
    """

    # GPT-4 API Call (Latest Method)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content
```

</br>

### â–¶ï¸ 5. Streamlit Implementation
- Loading RAG-Related Functions
```python
def load_rag_functions():
    with open(rag_application_path, "r", encoding="utf-8") as f:
        nb_content = nbformat.read(f, as_version=4)
    
    exporter = PythonExporter()
    source_code, _ = exporter.from_notebook_node(nb_content)
    
    exec(source_code, globals())

load_rag_functions()
```

- Load FAISS database and question data
```python
faiss_index_path = "faiss_index.bin"  # FAISS ì¸ë±ìŠ¤ ê²½ë¡œ
index = faiss.read_index(faiss_index_path)  # FAISS ì¸ë±ìŠ¤ ì½ê¸°

faiss_data_path = "faiss_data.pkl"  # FAISS ë°ì´í„° ê²½ë¡œ
try:
    with open(faiss_data_path, "rb") as f:
        faiss_data = pickle.load(f)  # ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ
except FileNotFoundError:
    faiss_data = None  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë°ì´í„°ëŠ” None
```

- ëœë¤ ë¬¸ì œ ê°€ì ¸ì˜¤ê¸° ë° Streamlit UI ì²˜ë¦¬
```python
def get_random_question_from_faiss():
    if faiss_data is not None and len(faiss_data) > 0:
        retrieved_data = random.choice(faiss_data)  # ëœë¤ ë¬¸ì œ ì„ íƒ
        if isinstance(retrieved_data, dict) and "question" in retrieved_data:
            question = retrieved_data["question"]
            options = retrieved_data.get("options", [])
            correct_answer = retrieved_data.get("answer", "")
            
            # ë°‘ì¤„ ì²˜ë¦¬ ì ìš©
            question = question.replace("effort", "<u>effort</u>")
            return question, options, correct_answer
    return None, None, None
```

- Streamlit UI êµ¬ì„±
```python
st.title("ğŸ“˜ RAG ê¸°ë°˜ ì˜ì–´ í•™ìŠµ ì±—ë´‡")  # ì›¹í˜ì´ì§€ ì œëª© ì„¤ì •

query_type = st.radio("ê²€ìƒ‰ ìœ í˜• ì„ íƒ", ["ì¼ë°˜ ì§ˆë¬¸", "ëœë¤ ë¬¸ì œ í’€ê¸°"])  # ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ë°›ì„ ì§ˆë¬¸ ìœ í˜• ì„ íƒ

if query_type == "ì¼ë°˜ ì§ˆë¬¸":
    query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")  # ì¼ë°˜ ì§ˆë¬¸ ì…ë ¥ë°›ê¸°
    if st.button("ì‘ë‹µ ìƒì„±"):  # ì‘ë‹µ ë²„íŠ¼ í´ë¦­ ì‹œ
        if query:
            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                answer = generate_response(query)  # GPT ëª¨ë¸ì„ ì´ìš©í•´ ë‹µë³€ ìƒì„±
            st.subheader("GPT-3.5ì˜ ë‹µë³€")
            st.markdown(answer, unsafe_allow_html=True)  # ì‘ë‹µ ì¶œë ¥

elif query_type == "ëœë¤ ë¬¸ì œ í’€ê¸°":
    if "current_question" not in st.session_state:
        st.session_state.current_question = None
        st.session_state.current_options = []
        st.session_state.correct_answer = None
        st.session_state.answered = False

    if st.button("ëœë¤ ë¬¸ì œ ì¶œì œ"):  # ëœë¤ ë¬¸ì œ ì¶œì œ ë²„íŠ¼ í´ë¦­ ì‹œ
        result = get_random_question_from_faiss()
        if result and all(result):  # ìœ íš¨í•œ ë¬¸ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´
            st.session_state.current_question, st.session_state.current_options, st.session_state.correct_answer = result
            st.session_state.answered = False
    
    if st.session_state.current_question:
        st.subheader("ğŸ“– ëœë¤ ë¬¸ì œ")
        st.markdown(st.session_state.current_question, unsafe_allow_html=True)

        selected_option = st.radio("ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”:", st.session_state.current_options, index=None)  # ì„ íƒì§€ í‘œì‹œ

        if st.button("ì •ë‹µ í™•ì¸"):  # ì •ë‹µ í™•ì¸ ë²„íŠ¼ í´ë¦­ ì‹œ
            if selected_option is None:
                st.warning("âš ï¸ ì •ë‹µì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
            else:
                st.session_state.answered = True
                if selected_option == st.session_state.correct_answer:
                    st.success("âœ… ì •ë‹µì…ë‹ˆë‹¤!")
                else:
                    st.error(f"âŒ ì˜¤ë‹µì…ë‹ˆë‹¤! ì •ë‹µì€: {st.session_state.correct_answer}")

        if st.session_state.answered:
            if st.button("ìƒˆë¡œìš´ ë¬¸ì œ ì¶œì œ"):  # ìƒˆë¡œìš´ ë¬¸ì œ ì¶œì œ ë²„íŠ¼ í´ë¦­ ì‹œ
                st.session_state.current_question = None
                st.session_state.current_options = []
                st.session_state.correct_answer = None
                st.session_state.answered = False
                st.rerun()  # í˜ì´ì§€ ìƒˆë¡œ ê³ ì¹¨
```
---

## ğŸ¬ìˆ˜í–‰ê²°ê³¼(í…ŒìŠ¤íŠ¸/ì‹œì—° í˜ì´ì§€)

## **1. ë¹ˆì¹¸ ë¬¸ì œ í•´ê²°**  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/c39017ae-5cb1-4718-b53b-9f78072266b6" width="600px" height="470px">
</p>

<br>  

PDF ë³€í™˜ ê³¼ì •ì—ì„œ ë¹ˆì¹¸ì„ í¬í•¨í•œ ì§€ë¬¸ì´ ëˆ„ë½ë˜ëŠ” ë¬¸ì œë¥¼ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì±—ë´‡ì´ ì •ìƒì ìœ¼ë¡œ ë¹ˆì¹¸ ë¬¸ì œë¥¼ ì œê³µí•˜ì§€ ëª»í•˜ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤.  

<br>  

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, JSON ë³€í™˜ í›„ ì‚¬ë¼ì§„ ë¹ˆì¹¸ì„ `_ (underscore)` ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ë¬¸ì œ í˜•ì‹ì„ ë³´ì™„í•˜ì˜€ìŠµë‹ˆë‹¤.  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/2e2d1116-64e3-4e0e-9c3b-919bede8010a" width="600px" height="470px">
</p>

<br>  

---

## **2. ë°‘ì¤„ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ ë¬¸ì œ í•´ê²°**  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/7737df6d-8643-40fe-ba37-f571d3a8df99" width="600px" height="430px">
</p>

<br>  

PDF ë³€í™˜ ê³¼ì •ì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ê°€ ì‚¬ë¼ì§€ëŠ” ë¬¸ì œë¥¼ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì„ íƒì§€ë‚˜ ì§€ë¬¸ ë‚´ ì¤‘ìš”í•œ ë¶€ë¶„ì´ ìœ ì‹¤ë˜ëŠ” í˜„ìƒì´ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤.  

<br>  

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, JSON íŒŒì¼ ë‚´ì—ì„œ ë°‘ì¤„ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ ì–‘ìª½ì— `<u>í•´ë‹¹í…ìŠ¤íŠ¸</u>`ë¥¼ ì‚½ì…í•˜ì—¬ ì›ë³¸ PDF ì„œì‹ì„ ìœ ì§€í•˜ë„ë¡ ì¡°ì •í•˜ì˜€ìŠµë‹ˆë‹¤.  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/d7652367-aaf7-440b-aeb3-96a4f7612bb3" width="600px" height="430px">
</p>

<br>  

---

## **3. ë””ë²„ê¹… ë©”ì‹œì§€ ì¶œë ¥ ë¬¸ì œ í•´ê²°**  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/cb1fee0a-83da-452f-9209-5b8a3f9e01f9" width="600px" height="430px">
</p>

<br>  

ì±—ë´‡ì˜ ì‘ë‹µ ê³¼ì •ì—ì„œ ì˜ë„ì¹˜ ì•Šê²Œ ë‚´ë¶€ ë””ë²„ê¹… ë©”ì‹œì§€ê°€ í•¨ê»˜ ì¶œë ¥ë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì‚¬ìš©ìê°€ ë¬¸ì œë¥¼ í‘¸ëŠ” ê³¼ì •ì—ì„œ ë¶ˆí•„ìš”í•œ DEBUG ë° INFO ë©”ì‹œì§€ê°€ ë…¸ì¶œë˜ëŠ” í˜„ìƒì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.  

<br>  

ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, `streamlit.py`ì—ì„œ ë¡œê¹… ë ˆë²¨ì„ ì¡°ì •í•˜ì—¬ DEBUG ë° INFO ë©”ì‹œì§€ê°€ ì¶œë ¥ë˜ì§€ ì•Šë„ë¡ ë³€ê²½í•˜ì˜€ìŠµë‹ˆë‹¤.  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/5dd23d3c-7536-4851-89a5-96d6f1d1b92e" width="600px" height="550px">
</p>

<br>  


## ğŸ“Œ ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•œ ì‚¬í•­
í˜„ì¬ ì±—ë´‡ì´ ì •ìƒì ìœ¼ë¡œ ë¹ˆì¹¸ ë¬¸ì œë¥¼ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ê°œì„ ë˜ì—ˆì§€ë§Œ, ë³´ë‹¤ í–¥ìƒëœ ì„±ëŠ¥ì„ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.
<br>
1. ì±—ë´‡ì´ ì˜ì–´ë¡œ ì‘ë‹µí•˜ëŠ” ë¬¸ì œ: ì±—ë´‡ì´ í•œêµ­ì–´ë¡œ ëœ ì§ˆë¬¸ì„ ë°›ì•˜ìŒì—ë„ ì¼ë¶€ ì‘ë‹µì´ ì˜ì–´ë¡œ ì¶œë ¥ë˜ëŠ” í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤.
2. ì§€ì‹œë¬¸, ì§€ë¬¸, ì„ íƒì§€ ì¤‘ ì¼ë¶€ê°€ ëˆ„ë½ë˜ëŠ” ë¬¸ì œ: JSON ë³€í™˜ ê³¼ì •ì—ì„œ íŠ¹ì • ìš”ì†Œ(ì§€ì‹œë¬¸, ì§€ë¬¸, ì„ íƒì§€)ì˜ ì¼ë¶€ê°€ ì •ìƒì ìœ¼ë¡œ ë³€í™˜ë˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.
3. ê·¸ë¦¼ì´ë‚˜ ê·¸ë˜í”„ í¬í•¨ ë¬¸ì œ: PDFì— í¬í•¨ëœ ê·¸ë¦¼, í‘œ, ê·¸ë˜í”„ ë“±ì˜ ìš”ì†Œê°€ í…ìŠ¤íŠ¸ ë³€í™˜ ê³¼ì •ì—ì„œ ëˆ„ë½ë˜ê±°ë‚˜ ì™œê³¡ë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

---
 
## ğŸ’­í•œ ì¤„ íšŒê³ 

ì„œì£¼í˜: OpenAIì˜ text-embedding-ada-002 ëª¨ë¸ì„ í™œìš©í•˜ë©°, ìµœì‹  ì„ë² ë”© ê¸°ìˆ ì˜ ì„±ëŠ¥ê³¼ í•œê³„ë¥¼ ì²´ê°í•œ í”„ë¡œì íŠ¸ì˜€ë‹¤.
<br>
ëŒ€ì„±ì›: ë°ì´í„°ë¥¼ ì˜¨ì „íˆ ì²˜ë¦¬í•˜ê³  ì›í•˜ëŠ” ê²°ê´ê°’ì„ ë„ì¶œí•´ë‚´ê¸° ìœ„í•´ì„œëŠ” ìƒê°ë³´ë‹¤ ë³µì¡í•œ ìˆ˜ì‘ì—…ì´ í•„ìš”í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ë‹¤.
<br>
ìœ¤ì •ì—°: ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ì„œ ë°ì´í„° ì²˜ë¦¬ ê³¼ì •ì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€, ê·¸ë¦¬ê³  ì„¸ì‹¬í•œ ì¡°ì •ì´ ê²°ê³¼ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ë‹¤.
