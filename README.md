# SKN07-3rd-3Team

# ğŸ“˜ RAG ê¸°ë°˜ ì˜ì–´ í•™ìŠµ ì±—ë´‡
 
## ğŸ‘¥ íŒ€ ì†Œê°œ
| <img src="https://github.com/user-attachments/assets/b5a17c3c-8415-409b-ae90-0a931e677fc3" width="250" height="250"/> | <img src="https://github.com/user-attachments/assets/005f1a53-0700-420e-8c62-ae1555dd538b" width="250" height="260"/> | <img src="https://github.com/user-attachments/assets/3009a31a-d5ab-469a-bf39-39e6c7779efe" width="250" height="250"/>  | 
|:----------:|:----------:|:----------:|
| ì˜ì–´ ì„ ìƒë‹˜ | êµ­ì–´ ì„ ìƒë‹˜ | ì‚¬íšŒ ì„ ìƒë‹˜ | 
| ì„œì£¼í˜ | ëŒ€ì„±ì› | ìœ¤ì •ì—° | 

<br>

---

## ğŸ“– í”„ë¡œì íŠ¸ ê°œìš”
- í”„ë¡œì íŠ¸ ëª…:  RAG ê¸°ë°˜ ì˜ì–´ í•™ìŠµ ì±—ë´‡
- í”„ë¡œì íŠ¸ ì†Œê°œ: AI ê³ ì¡¸ ê²€ì •ê³ ì‹œ í•™ìŠµ íŠœí„°ëŠ” ê²€ì •ê³ ì‹œë¥¼ ì¤€ë¹„í•˜ëŠ” í•™ìŠµìë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. 2018ë…„ë¶€í„° 2024ë…„ê¹Œì§€ 7ë…„ì¹˜ì˜ ê³ ì¡¸ ê²€ì •ê³ ì‹œ ê¸°ì¶œ ë¬¸ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©° ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ì •ë‹µê³¼ í•´ì„¤ì„ ì œê³µí•©ë‹ˆë‹¤.
  ì´ í”„ë¡œì íŠ¸ëŠ” **Retrieval-Augmented Generation (RAG)** ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì˜ì–´ í•™ìŠµì„ ë„ì™€ì£¼ëŠ” **Streamlit ê¸°ë°˜ ì±—ë´‡**ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì¼ë°˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ FAISS ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëœë¤ìœ¼ë¡œ ì¶œì œë˜ëŠ” ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  
- í”„ë¡œì íŠ¸ í•„ìš”ì„±(ë°°ê²½):
  - ê¸°ì¡´ì˜ ê²€ì •ê³ ì‹œ í•™ìŠµ ìë£ŒëŠ” ê°œë³„ì ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ì¦‰ê°ì ì¸ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì´ ë¶€ì¡±í•©ë‹ˆë‹¤.
  - ì‹¤ì œ ê¸°ì¶œëœ ë¬¸ì œë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìœ¼ë¯€ë¡œ í•™ìŠµìëŠ” ê²€ì •ê³ ì‹œ ëŒ€ë¹„ì— ìˆì–´ ë³´ë‹¤ ì²´ê³„ì ì´ê³  íš¨ìœ¨ì ì¸ í•™ìŠµì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  - ê²½ì œì , í™˜ê²½ì  ìš”ì¸ìœ¼ë¡œ ì¸í•´ ì •ê·œ êµìœ¡ì„ ë°›ê¸° ì–´ë ¤ìš´ í•™ìŠµìë“¤ì—ê²Œ ê³µìµì ì¸ í•™ìŠµ ê¸°íšŒë¥¼ ì œê³µí•˜ë©°, êµìœ¡ ê²©ì°¨ë¥¼ ì¤„ì´ëŠ” ë° ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- í”„ë¡œì íŠ¸ ëª©í‘œ:
  ë³¸ í”„ë¡œì íŠ¸ëŠ” AI ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ í•™ìŠµìê°€ ê²€ì •ê³ ì‹œë¥¼ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ì¤€ë¹„í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
  - Q&A ì„œë¹„ìŠ¤ ê°œë°œ: 2018ë…„ë¶€í„° 2024ë…„ê¹Œì§€ì˜ ê³ ì¡¸ ê²€ì •ê³ ì‹œ ê¸°ì¶œë¬¸ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ CHAT GPT APIë¥¼ í™œìš©í•˜ì—¬ AIê°€ ì§ˆë¬¸ì— ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
  - ìì—°ì–´ ì²˜ë¦¬(NLP) ë° LLM(Chat GPT API) í™œìš©: í…ìŠ¤íŠ¸ ë¶„ì„ê³¼ ë¬¸ì„œ ì´í•´ ê¸°ìˆ ì„ ì ìš©í•˜ì—¬ ì§ˆì˜ì‘ë‹µ ì •í™•ë„ë¥¼ í–¥ìƒí•©ë‹ˆë‹¤.
  - ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤ ì œê³µ: í•™ìŠµìê°€ ì‰½ê²Œ ì ‘ê·¼í•˜ê³  í™œìš©í•  ìˆ˜ ìˆëŠ” ì§ê´€ì ì¸ í™˜ê²½ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
  - í•™ìŠµ íš¨ê³¼ ì¦ëŒ€: AIë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì‘ë‹µ ì‹œìŠ¤í…œìœ¼ë¡œ íš¨ìœ¨ì ì¸ í•™ìŠµì„ ì§€ì›í•©ë‹ˆë‹¤.
  - ë§ì¶¤í˜• í•™ìŠµ ì œê³µ: í•™ìŠµì´ í•„ìš”í•œ ë¬¸ì œ ìœ í˜•ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë¬¸ì œì™€ ë‹µ, í•´ì„¤ì„ ì œê³µí•˜ì—¬ í•™ìŠµì„ ì¦ì§„í•©ë‹ˆë‹¤.

---

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥ ì†Œê°œ

1. **ì¼ë°˜ ì§ˆë¬¸ ì‘ë‹µ**
   - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ëŒ€í•´ OpenAI GPT-3.5ê°€ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
2. **ëœë¤ ë¬¸ì œ í’€ê¸°**
   - FAISS ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì˜ì–´ ë¬¸ì œë¥¼ ëœë¤ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ ì‚¬ìš©ìê°€ ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
   - ì„ íƒì§€ë¥¼ ì œê³µí•˜ë©° ì •ë‹µì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

<img src="https://github.com/user-attachments/assets/81339928-6c06-4bf1-8871-71630856ecac" alt="í”„ë¡œì íŠ¸ êµ¬ì¡°" width="800px">

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ



---

## ğŸ“‘ ì£¼ìš” í”„ë¡œì‹œì €

### â–¶ï¸ 1. ë°ì´í„° ìˆ˜ì§‘ _ ì›¹ í¬ë¡¤ë§ (í•œêµ­êµìœ¡ê³¼ì •í‰ê°€ì›)
- ë©”ì¸ í˜ì´ì§€ì—ì„œ ê° ì—°ë„, í•™ë ¥ë¶„ë¥˜, ì°¨ìˆ˜, ê³¼ëª©ë³„ ì½”ë“œë²ˆí˜¸ ì¶”ì¶œ
```python
code_dict = {}
tmp = 1
while True:   # ëª¨ë“  í˜ì´ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    url = f'https://www.kice.re.kr/boardCnts/list.do?type=default&page={tmp}&selLimitYearYn=Y&selStartYear=2018&C06=&boardID=1500211&C05=&C04=&C03=&searchType=S&C02=&C01='
    re = requests.get(url)
    soup = BeautifulSoup(re.text, 'html.parser')
    
    if soup.find('td').text.strip() == 'ë“±ë¡ëœ ê²Œì‹œë¬¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.':
        break
        
    info = soup.find('tbody').find_all('tr')
    
    for i in info:
        code = i.find_all('td')[0].text
        year = i.find_all('td')[1].text
        edu = i.find_all('td')[2].text
        cnt = i.find_all('td')[3].text
        subject = i.find_all('td')[4].find('a')['title']
        # ì›í•˜ëŠ” ìë£Œ ì •ë³´ ì„ íƒ
        if edu == 'ê³ ì¡¸í•™ë ¥' and subject == 'ì˜ì–´':
            code_dict[code] = f'{year}_{edu}_{cnt}_{subject}'
    
    tmp += 1
```
![image](https://github.com/user-attachments/assets/be19cd7c-60ca-4ed9-a431-04b07a2ace09)
- ì¶”ì¶œëœ ì½”ë“œë²ˆí˜¸ë¡œ ì„¸ë¶€ í˜ì´ì§€ ì ‘ì† í›„ PDF íŒŒì¼ ì €ì¥
```python
for code in code_dict.keys():
    down_url = f'https://www.kice.re.kr/boardCnts/view.do?boardID=1500211&boardSeq={code}&lev=0&m=030305&searchType=S&statusYN=W&page=1&s=kice'
    down_re = requests.get(down_url)
    down_soup = BeautifulSoup(down_re.text)
    tmp_url = down_soup.find(class_='fieldBox').find('a')['href']
    pdf_url = 'https://www.kice.re.kr' + tmp_url
    file_path = f'./data/ì •ë‹µ/{code_dict[code]}.pdf'
    
    response = requests.get(pdf_url)
    # ì‘ë‹µ ìƒíƒœ ì½”ë“œê°€ 200(ì„±ê³µ)ì¸ ê²½ìš°ì—ë§Œ íŒŒì¼ ì €ì¥
    if response.status_code == 200:
        with open(file_path, 'wb') as file:
            file.write(response.content)  # PDF íŒŒì¼ ì €ì¥
```

</br>

### â–¶ï¸ 2. ë°ì´í„° ì¶”ì¶œ
### 2-1) ê³ ë“± ì˜ì–´ ë¬¸ì œ ì¶”ì¶œ

- PDFì—ì„œ ì™¼ìª½/ì˜¤ë¥¸ìª½ ë¬¸í•­ì„ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì •ë¦¬í•˜ì—¬ ì¶”ì¶œ
```python
def extract_text_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        combined_text_list = []

        for page in pdf.pages:
            width, height = page.width, page.height

            # ì™¼ìª½ ë¬¸í•­ (í˜ì´ì§€ë³„ ì™¼ìª½ ë¨¼ì €)
            left_bbox = (0, 0, width / 2, height)
            left_crop = page.within_bbox(left_bbox)
            left_text = left_crop.extract_text()
            if left_text:
                combined_text_list.append(clean_text(left_text))  # ì •ë¦¬ í›„ ì¶”ê°€

            # ì˜¤ë¥¸ìª½ ë¬¸í•­ (í˜ì´ì§€ë³„ ì˜¤ë¥¸ìª½ ë‚˜ì¤‘)
            right_bbox = (width / 2, 0, width, height)
            right_crop = page.within_bbox(right_bbox)
            right_text = right_crop.extract_text()
            if right_text:
                combined_text_list.append(clean_text(right_text))
```

- OCR ì´ë¯¸ì§€ PDF ì²˜ë¦¬ (í˜ì´ì§€ë³„ ì™¼ìª½ â†’ ì˜¤ë¥¸ìª½)
```python
def extract_text_from_image_pdf(pdf_path):
    images = convert_from_path(pdf_path, dpi=300)
    combined_text_list = []

    for img in images:
        width, height = img.size

        # ì™¼ìª½ ë¬¸í•­ OCR
        left_crop = img.crop((0, 0, width // 2, height))
        left_text = pytesseract.image_to_string(left_crop, lang="eng+kor", config="--psm 6")
        combined_text_list.append(clean_text(left_text))

        # ì˜¤ë¥¸ìª½ ë¬¸í•­ OCR
        right_crop = img.crop((width // 2, 0, width, height))
        right_text = pytesseract.image_to_string(right_crop, lang="eng+kor", config="--psm 6")
        combined_text_list.append(clean_text(right_text))

    return "\n".join(combined_text_list)
```

### 2-2) ê³ ë“± ì˜ì–´ ì •ë‹µ ì¶”ì¶œ
- PDFì—ì„œ ì˜ì–´ ì •ë‹µ ì¶”ì¶œ (OCR í¬í•¨)
```python
def extract_english_answers_from_pdf(pdf_path):
    answers = {}

    # 1ï¸âƒ£ PDFì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    with pdfplumber.open(pdf_path) as pdf:
        text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])

    # 2ï¸âƒ£ OCR ì ìš© (í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìœ¼ë©´ OCR ì‚¬ìš©)
    if not text.strip():
        text = extract_text_from_image_pdf(pdf_path)

    # 3ï¸âƒ£ OCRë¡œ ì¶”ì¶œí•œ ì›ë³¸ í…ìŠ¤íŠ¸ ì¶œë ¥ (ë””ë²„ê¹… ëª©ì )
    print("\nğŸ“ OCR EXTRACTED TEXT FROM PDF:", pdf_path)
    print(text[:1000])  # ì²˜ìŒ 1000ìë§Œ ì¶œë ¥

    # 4ï¸âƒ£ "ì˜ì–´ ì •ë‹µí‘œ" ë˜ëŠ” "3êµì‹œ ì˜ì–´" í¬í•¨ëœ ë¶€ë¶„ ì°¾ê¸°
    match = re.search(r"(?:ì˜ì–´ ì •ë‹µí‘œ|3êµì‹œ ì˜ì–´|ì˜ì–´)([\s\S]+?)(?=\n\w+ ì •ë‹µí‘œ|\Z)", text)
    if match:
        english_answers_section = match.group(1).strip()
    else:
        print(f"âš  ì˜ì–´ ì •ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {pdf_path}")
        return None

    # 5ï¸âƒ£ ì •ë‹µ íŒ¨í„´ ì¶”ì¶œ (ë””ë²„ê¹…ìš© ì¶œë ¥ ì¶”ê°€)
    extracted_text = convert_korean_numbers(english_answers_section)
    print("\nğŸ” EXTRACTED ENGLISH ANSWERS SECTION:")
    print(extracted_text[:500])  # ì²˜ìŒ 500ìë§Œ ì¶œë ¥

    # 6ï¸âƒ£ ë¬¸í•­ë²ˆí˜¸ & ì •ë‹µ ì¶”ì¶œ
    answer_pattern = re.findall(r"(\d+)\s+([â‘ â‘¡â‘¢â‘£1-4])", extracted_text)

    # ğŸ”¥ ë””ë²„ê¹…: ì¶”ì¶œëœ ì •ë‹µ ì¶œë ¥
    print("\nğŸ” Extracted Answers Dictionary:", answer_pattern)

    for q_num, ans in answer_pattern:
        answers[q_num] = ans

    return answers
```

### 2-3) ê³ ë“± ì˜ì–´ ë¬¸ì œ, ì •ë‹µ jsoníŒŒì¼ í•©ì¹˜ê¸°
- íŒŒì¼ëª… ì •ë¦¬ (ì •ë‹µ íŒŒì¼ëª…ê³¼ ë¬¸ì œ íŒŒì¼ëª… ì¼ì¹˜í•˜ë„ë¡ ë³€í™˜)
```python
def clean_filename(filename):
    return filename.replace("_ê³ ë“±_ì •ë‹µ.pdf", "_ê³ ë“±_ì˜ì–´.pdf")  # ì •ë‹µ íŒŒì¼ëª…ì„ ë¬¸ì œ íŒŒì¼ëª…ê³¼ ë§ì¶¤
```

- ë³€í™˜ëœ ì •ë‹µ ë°ì´í„° í‚¤ ê°’ ìˆ˜ì •
```python
answers_data_fixed = {clean_filename(k): v for k, v in answers_data.items()}\
```

- ë¬¸ì œì™€ ì •ë‹µ ë§¤ì¹­
```python
merged_data = {}

for file_name, question_content in questions_data.items():
    matched_file = clean_filename(file_name)
    if matched_file in answers_data_fixed:  # ì •ë‹µì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
        merged_data[file_name] = {
            "questions": question_content,
            "answers": answers_data_fixed[matched_file]
        }
    else:
        print(f"âš  ì •ë‹µì´ ì—†ëŠ” ë¬¸ì œ íŒŒì¼: {file_name}")
```

</br>

### â–¶ï¸ 3. ì„ë² ë”©
- OpenAIì˜ "text-embedding-ada-002" ëª¨ë¸ë¥¼ ì‚¬ìš©í•´ ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
```python
def get_embedding(text):
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding  # ìµœì‹  API ë°©ì‹ ì ìš©

# ëª¨ë“  ì§ˆë¬¸ì„ ì„ë² ë”© ë³€í™˜
question_embeddings = [get_embedding(q) for q in questions]
```

- FAISS ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
```python
embedding_dim = 1536  # ë²¡í„° ì°¨ì› ì„¤ì •
index = faiss.IndexFlatL2(embedding_dim)  # FAISS ì¸ë±ìŠ¤ ìƒì„±
question_vectors = np.array(question_embeddings).astype("float32")  # ì„ë² ë”© ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
index.add(question_vectors)  # FAISS ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
```

- FAISSë¥¼ ì´ìš©í•œ ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
```python
def search_similar_questions(query, top_k=3):
    # ì…ë ¥ ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
    query_vector = np.array(get_embedding(query)).astype("float32").reshape(1, -1)

    # ê°€ì¥ ê°€ê¹Œìš´ ì§ˆë¬¸ ê²€ìƒ‰
    distances, indices = index.search(query_vector, top_k)

    # ê²°ê³¼ ì¶œë ¥
    print("\n[ê°€ì¥ ìœ ì‚¬í•œ ì§ˆë¬¸ë“¤]")
    for i in range(top_k):
        idx = indices[0][i]
        print(f"{i+1}. {questions[idx]} (ê±°ë¦¬: {distances[0][i]:.4f})")
```

- FAISS ì¸ë±ìŠ¤ ì €ì¥
```python
faiss.write_index(index, "faiss_index.bin")
```

</br>

### â–¶ï¸ 4. Streamlit êµ¬í˜„
- RAG ê´€ë ¨ í•¨ìˆ˜ ë¡œë“œ
```python
def load_rag_functions():
    with open(rag_application_path, "r", encoding="utf-8") as f:
        nb_content = nbformat.read(f, as_version=4)
    
    exporter = PythonExporter()
    source_code, _ = exporter.from_notebook_node(nb_content)
    
    exec(source_code, globals())

load_rag_functions()
```

- FAISS ë°ì´í„°ë² ì´ìŠ¤ ë° ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ
```python
faiss_index_path = "faiss_index.bin"  # FAISS ì¸ë±ìŠ¤ ê²½ë¡œ
index = faiss.read_index(faiss_index_path)  # FAISS ì¸ë±ìŠ¤ ì½ê¸°

faiss_data_path = "faiss_data.pkl"  # FAISS ë°ì´í„° ê²½ë¡œ
try:
    with open(faiss_data_path, "rb") as f:
        faiss_data = pickle.load(f)  # ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ
except FileNotFoundError:
    faiss_data = None  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë°ì´í„°ëŠ” None
```

- ëœë¤ ë¬¸ì œ ê°€ì ¸ì˜¤ê¸° ë° Streamlit UI ì²˜ë¦¬
```python
def get_random_question_from_faiss():
    if faiss_data is not None and len(faiss_data) > 0:
        retrieved_data = random.choice(faiss_data)  # ëœë¤ ë¬¸ì œ ì„ íƒ
        if isinstance(retrieved_data, dict) and "question" in retrieved_data:
            question = retrieved_data["question"]
            options = retrieved_data.get("options", [])
            correct_answer = retrieved_data.get("answer", "")
            
            # ë°‘ì¤„ ì²˜ë¦¬ ì ìš©
            question = question.replace("effort", "<u>effort</u>")
            return question, options, correct_answer
    return None, None, None
```

- Streamlit UI êµ¬ì„±
```python
st.title("ğŸ“˜ RAG ê¸°ë°˜ ì˜ì–´ í•™ìŠµ ì±—ë´‡")  # ì›¹í˜ì´ì§€ ì œëª© ì„¤ì •

query_type = st.radio("ê²€ìƒ‰ ìœ í˜• ì„ íƒ", ["ì¼ë°˜ ì§ˆë¬¸", "ëœë¤ ë¬¸ì œ í’€ê¸°"])  # ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ë°›ì„ ì§ˆë¬¸ ìœ í˜• ì„ íƒ

if query_type == "ì¼ë°˜ ì§ˆë¬¸":
    query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")  # ì¼ë°˜ ì§ˆë¬¸ ì…ë ¥ë°›ê¸°
    if st.button("ì‘ë‹µ ìƒì„±"):  # ì‘ë‹µ ë²„íŠ¼ í´ë¦­ ì‹œ
        if query:
            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                answer = generate_response(query)  # GPT ëª¨ë¸ì„ ì´ìš©í•´ ë‹µë³€ ìƒì„±
            st.subheader("GPT-3.5ì˜ ë‹µë³€")
            st.markdown(answer, unsafe_allow_html=True)  # ì‘ë‹µ ì¶œë ¥

elif query_type == "ëœë¤ ë¬¸ì œ í’€ê¸°":
    if "current_question" not in st.session_state:
        st.session_state.current_question = None
        st.session_state.current_options = []
        st.session_state.correct_answer = None
        st.session_state.answered = False

    if st.button("ëœë¤ ë¬¸ì œ ì¶œì œ"):  # ëœë¤ ë¬¸ì œ ì¶œì œ ë²„íŠ¼ í´ë¦­ ì‹œ
        result = get_random_question_from_faiss()
        if result and all(result):  # ìœ íš¨í•œ ë¬¸ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´
            st.session_state.current_question, st.session_state.current_options, st.session_state.correct_answer = result
            st.session_state.answered = False
    
    if st.session_state.current_question:
        st.subheader("ğŸ“– ëœë¤ ë¬¸ì œ")
        st.markdown(st.session_state.current_question, unsafe_allow_html=True)

        selected_option = st.radio("ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”:", st.session_state.current_options, index=None)  # ì„ íƒì§€ í‘œì‹œ

        if st.button("ì •ë‹µ í™•ì¸"):  # ì •ë‹µ í™•ì¸ ë²„íŠ¼ í´ë¦­ ì‹œ
            if selected_option is None:
                st.warning("âš ï¸ ì •ë‹µì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
            else:
                st.session_state.answered = True
                if selected_option == st.session_state.correct_answer:
                    st.success("âœ… ì •ë‹µì…ë‹ˆë‹¤!")
                else:
                    st.error(f"âŒ ì˜¤ë‹µì…ë‹ˆë‹¤! ì •ë‹µì€: {st.session_state.correct_answer}")

        if st.session_state.answered:
            if st.button("ìƒˆë¡œìš´ ë¬¸ì œ ì¶œì œ"):  # ìƒˆë¡œìš´ ë¬¸ì œ ì¶œì œ ë²„íŠ¼ í´ë¦­ ì‹œ
                st.session_state.current_question = None
                st.session_state.current_options = []
                st.session_state.correct_answer = None
                st.session_state.answered = False
                st.rerun()  # í˜ì´ì§€ ìƒˆë¡œ ê³ ì¹¨
```
---

## ğŸ¬ìˆ˜í–‰ê²°ê³¼(í…ŒìŠ¤íŠ¸/ì‹œì—° í˜ì´ì§€)

1. ë¹ˆì¹¸
<img src="https://github.com/user-attachments/assets/c39017ae-5cb1-4718-b53b-9f78072266b6" width="450px" height="430px"> 
PDF ë³€í™˜ ê³¼ì •ì—ì„œ ë¹ˆì¹¸ì„ í¬í•¨í•œ ì§€ë¬¸ì´ ëˆ„ë½ë˜ëŠ” ë¬¸ì œë¥¼ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.

JSON ë³€í™˜ í›„ ë¹ˆì¹¸ì´ ì‚¬ë¼ì§€ëŠ” í˜„ìƒì„ í•´ê²°í•˜ê¸° ìœ„í•´, _ (underscore) ê¸°í˜¸ë¥¼ Jsonì— ì§ì ‘ ì¶”ê°€í•˜ì—¬ ë¬¸ì œ í˜•ì‹ì„ ë³´ì™„í•˜ì˜€ìŠµë‹ˆë‹¤.
<img src="https://github.com/user-attachments/assets/2e2d1116-64e3-4e0e-9c3b-919bede8010a" width="500px" height="470px">

3. ë°‘ì¤„ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸
<img src="https://github.com/user-attachments/assets/7737df6d-8643-40fe-ba37-f571d3a8df99" width="450px" height="430px"> 
PDF ë³€í™˜ ê³¼ì •ì—ì„œ ë°‘ì¤„ ì¹œ í…ìŠ¤íŠ¸ê°€ ì‚¬ë¼ì§€ëŠ” ë¬¸ì œë¥¼ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.

<img src="https://github.com/user-attachments/assets/d7652367-aaf7-440b-aeb3-96a4f7612bb3" width="450px" height="430px"> 
ì›ë³¸ PDFì˜ ì„œì‹ê³¼ ë™ì¼í•œ í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ë„ë¡ JSON íŒŒì¼ ë‚´ì—ì„œ ë°‘ì¤„ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ ì–‘ìª½ì— <u>í•´ë‹¹í…ìŠ¤íŠ¸</u>ë¥¼ ì‚½ì…í•˜ì˜€ìŠµë‹ˆë‹¤.

4. ë””ë²„ê¹… ì¶œë ¥
<img src="https://github.com/user-attachments/assets/cb1fee0a-83da-452f-9209-5b8a3f9e01f9" width="450px" height="430px">
ì˜ë„ì¹˜ ì•Šê²Œ ë‚´ë¶€ ë””ë²„ê¹… ë©”ì‹œì§€ê°€ ì±—ë´‡ì˜ ì‘ë‹µì— í¬í•¨ë˜ëŠ” í˜„ìƒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

<img src="https://github.com/user-attachments/assets/5dd23d3c-7536-4851-89a5-96d6f1d1b92e" width="450px" height="430px">

streamlit.pyì—ì„œ ë¡œê¹…ë ˆë²¨ì„ ì¡°ì •í•˜ì—¬ ë¶ˆí•„ìš”í•œ DEBUG ë° INFO ë©”ì‹œì§€ê°€ ì¶œë ¥ë˜ì§€ ì•Šë„ë¡ ë³€ê²½í•˜ì˜€ìŠµë‹ˆë‹¤.


---
 
## ğŸ’­í•œ ì¤„ íšŒê³ 
