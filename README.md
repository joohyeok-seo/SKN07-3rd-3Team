# SKN07-3rd-3Team

# üìò RAG-based English Learning Chatbot
 
## üë• Team Introduction
| <img src="https://github.com/user-attachments/assets/b5a17c3c-8415-409b-ae90-0a931e677fc3" width="250" height="250"/> | <img src="https://github.com/user-attachments/assets/005f1a53-0700-420e-8c62-ae1555dd538b" width="250" height="260"/> | <img src="https://github.com/user-attachments/assets/3009a31a-d5ab-469a-bf39-39e6c7779efe" width="250" height="250"/>  | 
|:----------:|:----------:|:----------:|
| English Teacher | Korean Teacher | Social Studies Teacher | 
| Joohyeok Seo | Sungwon Dae | Jungyeon Yoon | 

<br>

---

## üìñ Project Overview
- Project Name: RAG-based English Learning Chatbot
- Project Description: The AI High School Equivalency Exam (GED) Learning Tutor is a service designed to assist learners preparing for the GED exam. It is based on seven years of past GED exam questions, from 2018 to 2024. Users can input their questions, and the AI provides correct answers along with explanations.
  This project utilizes Retrieval-Augmented Generation (RAG) technology to facilitate English learning through a Streamlit-based chatbot. Users can either ask general questions or solve randomly generated questions from the FAISS database.
  
- Project Necessity (Background):
  - Traditional GED study materials lack an interactive system that provides instant responses to individual questions.
  - Since this system is designed based solely on past exam questions, learners can systematically and efficiently prepare for the GED exam.
  - The project aims to provide a public learning opportunity for students facing economic or environmental challenges that make formal education difficult, contributing to reducing the education gap.

- Project Objectives:
  This project aims to help learners prepare for the GED exam more effectively using AI technology.
  - Develop a Q&A Service: Utilize ChatGPT API to generate AI-based responses to user queries, based on GED exam questions from 2018 to 2024.
  - Implement NLP and LLM (ChatGPT API): Apply text analysis and document comprehension techniques to improve the accuracy of responses.
  - Provide a User-Friendly Interface: Design an intuitive and accessible learning environment for students.
  - Enhance Learning Efficiency: Offer a real-time AI-powered response system to facilitate effective learning.
  - Deliver Personalized Learning: Analyze the user's weak areas and provide targeted questions, answers, and explanations to support their learning progress.

---

## üöÄ Key Features

1. **General Question Response**
   - Generates responses using OpenAI GPT-3.5 based on user-input questions.
2. **Random Quiz Mode**
   - Retrieves random English questions from the FAISS database, allowing users to practice.
   - Provides multiple-choice options and allows users to check the correct answer.

---

## üìÇ Project Structure

<img src="https://github.com/user-attachments/assets/81339928-6c06-4bf1-8871-71630856ecac" alt="Project Structure" width="800px">

---

## üîß Technology Stack
<p align="center">
  <img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/git-F05032?style=flat-square&logo=git&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/python-3776AB?style=flat-square&logo=python&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/streamlit-FF4B4B?style=flat-square&logo=streamlit&logoColor=white" width="150" height="45" />
</p>
<br>
<p align="center">
  <img src="https://img.shields.io/badge/jupyter-F37626?style=flat-square&logo=jupyter&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/openai-412991?style=flat-square&logo=openai&logoColor=white" width="150" height="45" />
  <img src="https://img.shields.io/badge/discord-5865F2?style=flat-square&logo=discord&logoColor=white" width="150" height="45" />
</p>



---

## üìë Main Procedures

### ‚ñ∂Ô∏è 1. Data Collection ‚Äì Web Crawling (Korea Institute for Curriculum and Evaluation, KICE)
- Extracting Code Numbers for Each Year, Education Level, Session, and Subject from the Main Page
```python
code_dict = {}
tmp = 1
while True:   # Retrieve All Page Information
    url = f'https://www.kice.re.kr/boardCnts/list.do?type=default&page={tmp}&selLimitYearYn=Y&selStartYear=2018&C06=&boardID=1500211&C05=&C04=&C03=&searchType=S&C02=&C01='
    re = requests.get(url)
    soup = BeautifulSoup(re.text, 'html.parser')
    
    if soup.find('td').text.strip() == 'No Registered Posts Available.':
        break
        
    info = soup.find('tbody').find_all('tr')
    
    for i in info:
        code = i.find_all('td')[0].text
        year = i.find_all('td')[1].text
        edu = i.find_all('td')[2].text
        cnt = i.find_all('td')[3].text
        subject = i.find_all('td')[4].find('a')['title']
        # Select Desired Data Information
        if edu == 'High School Equivalency Level' and subject == 'English':
            code_dict[code] = f'{year}_{edu}_{cnt}_{subject}'
    
    tmp += 1
```
![image](https://github.com/user-attachments/assets/be19cd7c-60ca-4ed9-a431-04b07a2ace09)
- Access Detailed Pages Using Extracted Code Numbers and Save PDF Files
```python
for code in code_dict.keys():
    down_url = f'https://www.kice.re.kr/boardCnts/view.do?boardID=1500211&boardSeq={code}&lev=0&m=030305&searchType=S&statusYN=W&page=1&s=kice'
    down_re = requests.get(down_url)
    down_soup = BeautifulSoup(down_re.text)
    tmp_url = down_soup.find(class_='fieldBox').find('a')['href']
    pdf_url = 'https://www.kice.re.kr' + tmp_url
    file_path = f'./data/Correct Answers/{code_dict[code]}.pdf'
    
    response = requests.get(pdf_url)
    # Save Files Only When the Response Status Code is 200 (Success)
    if response.status_code == 200:
        with open(file_path, 'wb') as file:
            file.write(response.content)  # Save PDF Files
```

</br>

### ‚ñ∂Ô∏è 2. Data Extraction
### 2-1) Extract High School English Questions

- Extract Questions from PDF and Arrange Left/Right Columns in the Correct Order
```python
def extract_text_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        combined_text_list = []

        for page in pdf.pages:
            width, height = page.width, page.height

            # Left Column Questions (Process Left Side First for Each Page)
            left_bbox = (0, 0, width / 2, height)
            left_crop = page.within_bbox(left_bbox)
            left_text = left_crop.extract_text()
            if left_text:
                combined_text_list.append(clean_text(left_text))  # Organize and Append Data

            # Right Column Questions (Process Right Side After Each Page)
            right_bbox = (width / 2, 0, width, height)
            right_crop = page.within_bbox(right_bbox)
            right_text = right_crop.extract_text()
            if right_text:
                combined_text_list.append(clean_text(right_text))
```

- OCR Processing for Image-based PDFs (Left to Right per Page)
```python
def extract_text_from_image_pdf(pdf_path):
    images = convert_from_path(pdf_path, dpi=300)
    combined_text_list = []

    for img in images:
        width, height = img.size

        # Left Column Question OCR
        left_crop = img.crop((0, 0, width // 2, height))
        left_text = pytesseract.image_to_string(left_crop, lang="eng+kor", config="--psm 6")
        combined_text_list.append(clean_text(left_text))

        # Right Column Question OCR
        right_crop = img.crop((width // 2, 0, width, height))
        right_text = pytesseract.image_to_string(right_crop, lang="eng+kor", config="--psm 6")
        combined_text_list.append(clean_text(right_text))

    return "\n".join(combined_text_list)
```

### 2-2) Extract High School English Answers
- Extract English Answers from PDF (Including OCR Processing)
```python
def extract_english_answers_from_pdf(pdf_path):
    answers = {}

    # 1Ô∏è‚É£ Extract Text Directly from PDF
    with pdfplumber.open(pdf_path) as pdf:
        text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])

    # 2Ô∏è‚É£ Apply OCR (Use OCR if Text is Empty)
    if not text.strip():
        text = extract_text_from_image_pdf(pdf_path)

    # 3Ô∏è‚É£ Output Raw Text Extracted via OCR (For Debugging Purposes)
    print("\nüìù OCR EXTRACTED TEXT FROM PDF:", pdf_path)
    print(text[:1000])  # Output First 1,000 Characters Only

    # 4Ô∏è‚É£ Find Sections Containing "English Answer Table" or "Session 3: English"
    match = re.search(r"(?:English Answer Table|Session 3: English|English)([\s\S]+?)(?=\n\w+ Answer Table|\Z)", text)
    if match:
        english_answers_section = match.group(1).strip()
    else:
        print(f"‚ö† English Answers Not Found: {pdf_path}")
        return None

    # 5Ô∏è‚É£ Extract Answer Patterns (Include Debugging Output)
    extracted_text = convert_korean_numbers(english_answers_section)
    print("\nüîç EXTRACTED ENGLISH ANSWERS SECTION:")
    print(extracted_text[:500])  # Output First 500 Characters Only

    # 6Ô∏è‚É£ Extract Question Numbers & Answers
    answer_pattern = re.findall(r"(\d+)\s+([‚ë†‚ë°‚ë¢‚ë£1-4])", extracted_text)

    # üî• Debugging: Output Extracted Answers
    print("\nüîé Extracted Answers Dictionary:", answer_pattern)

    for q_num, ans in answer_pattern:
        answers[q_num] = ans

    return answers
```

### 2-3) Merge High School English Questions and Answers into a JSON File
- Rename Files to Match Question and Answer Filenames
```python
def clean_filename(filename):
    return filename.replace("_High_School_Answers.pdf", "_High_School_English.pdf")  # Match Answer Filenames with Question Filenames
```

- Modify Key Values in the Converted Answer Data
```python
answers_data_fixed = {clean_filename(k): v for k, v in answers_data.items()}\
```

- Match Questions with Answers
```python
merged_data = {}

for file_name, question_content in questions_data.items():
    matched_file = clean_filename(file_name)
    if matched_file in answers_data_fixed:  # Add Only If an Answer Exists
        merged_data[file_name] = {
            "questions": question_content,
            "answers": answers_data_fixed[matched_file]
        }
    else:
        print(f"‚ö† Question Files Without Answers: {file_name}")
```

</br>

### ‚ñ∂Ô∏è 3. Embedding
- OpenAIÏùò "text-embedding-ada-002" Convert Questions into Vectors Using a Model
```python
def get_embedding(text):
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding  # Apply the Latest API Method

# Convert All Questions into Embeddings
question_embeddings = [get_embedding(q) for q in questions]
```

- Create FAISS Database
```python
embedding_dim = 1536  # Set Vector Dimensions
index = faiss.IndexFlatL2(embedding_dim)  # Create FAISS Index
question_vectors = np.array(question_embeddings).astype("float32")  # Convert Embedding Data to NumPy Array
index.add(question_vectors)  # FAISS Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï∂îÍ∞Ä
```

- Search for Similar Questions Using FAISS
```python
def search_similar_questions(query, top_k=3):
    # Convert Input Question into a Vector
    query_vector = np.array(get_embedding(query)).astype("float32").reshape(1, -1)

    # Search for the Closest Question
    distances, indices = index.search(query_vector, top_k)

    # Display Results
    print("\n[Most Similar Questions]")
    for i in range(top_k):
        idx = indices[0][i]
        print(f"{i+1}. {questions[idx]} (Í±∞Î¶¨: {distances[0][i]:.4f})")
```

- Save FAISS Index
```python
faiss.write_index(index, "faiss_index.bin")
```

</br>

### ‚ñ∂Ô∏è 4. Improve Performance with RAG (Retrieval-Augmented Generation)
- OpenAI Embedding
```python
client = openai.OpenAI()

# Embedding Conversion Function
def get_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding  # Apply Latest API Method
```
- Search for Similar Questions in FAISS
```python
def search_similar_questions(query, top_k=3):
    query_vector = np.array(get_embedding(query)).astype("float32").reshape(1, -1)
    distances, indices = index.search(query_vector, top_k)

    # Generate List of Similar Questions
    similar_questions = [questions[idx] for idx in indices[0]]

    print("\n[Most Similar Questions]")
    for i, question in enumerate(similar_questions):
        print(f"{i+1}. {question} (Similarity Distance: {distances[0][i]:.4f})")

    return similar_questions
```
- Connect to GPT-4 for Final RAG Response Generation
```python
def generate_response(query):
    similar_questions = search_similar_questions(query, top_k=3)     # Find Similar Questions
    context = "\n".join(similar_questions)     # Use Retrieved Questions as Prompt Context

    # Setting up GPT-4 Prompt
    prompt = f"""
    You are an AI assistant. Use the following context to answer the question.

    Context:
    {context}

    Question: {query}

    Answer:
    """

    # GPT-4 API Call (Latest Method)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content
```

</br>

### ‚ñ∂Ô∏è 5. Streamlit Implementation
- Loading RAG-Related Functions
```python
def load_rag_functions():
    with open(rag_application_path, "r", encoding="utf-8") as f:
        nb_content = nbformat.read(f, as_version=4)
    
    exporter = PythonExporter()
    source_code, _ = exporter.from_notebook_node(nb_content)
    
    exec(source_code, globals())

load_rag_functions()
```

- Load FAISS database and question data
```python
faiss_index_path = "faiss_index.bin"  # FAISS Ïù∏Îç±Ïä§ Í≤ΩÎ°ú
index = faiss.read_index(faiss_index_path)  # FAISS Ïù∏Îç±Ïä§ ÏùΩÍ∏∞

faiss_data_path = "faiss_data.pkl"  # FAISS Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú
try:
    with open(faiss_data_path, "rb") as f:
        faiss_data = pickle.load(f)  # ÏßàÎ¨∏ Îç∞Ïù¥ÌÑ∞ Î°úÎìú
except FileNotFoundError:
    faiss_data = None  # ÌååÏùºÏù¥ ÏóÜÏúºÎ©¥ Îç∞Ïù¥ÌÑ∞Îäî None
```

- ÎûúÎç§ Î¨∏Ï†ú Í∞ÄÏ†∏Ïò§Í∏∞ Î∞è Streamlit UI Ï≤òÎ¶¨
```python
def get_random_question_from_faiss():
    if faiss_data is not None and len(faiss_data) > 0:
        retrieved_data = random.choice(faiss_data)  # ÎûúÎç§ Î¨∏Ï†ú ÏÑ†ÌÉù
        if isinstance(retrieved_data, dict) and "question" in retrieved_data:
            question = retrieved_data["question"]
            options = retrieved_data.get("options", [])
            correct_answer = retrieved_data.get("answer", "")
            
            # Î∞ëÏ§Ñ Ï≤òÎ¶¨ Ï†ÅÏö©
            question = question.replace("effort", "<u>effort</u>")
            return question, options, correct_answer
    return None, None, None
```

- Streamlit UI Íµ¨ÏÑ±
```python
st.title("üìò RAG Í∏∞Î∞ò ÏòÅÏñ¥ ÌïôÏäµ Ï±óÎ¥á")  # ÏõπÌéòÏù¥ÏßÄ Ï†úÎ™© ÏÑ§Ï†ï

query_type = st.radio("Í≤ÄÏÉâ Ïú†Ìòï ÏÑ†ÌÉù", ["ÏùºÎ∞ò ÏßàÎ¨∏", "ÎûúÎç§ Î¨∏Ï†ú ÌíÄÍ∏∞"])  # ÏÇ¨Ïö©ÏûêÎ°úÎ∂ÄÌÑ∞ ÏûÖÎ†•Î∞õÏùÑ ÏßàÎ¨∏ Ïú†Ìòï ÏÑ†ÌÉù

if query_type == "ÏùºÎ∞ò ÏßàÎ¨∏":
    query = st.text_input("ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî:")  # ÏùºÎ∞ò ÏßàÎ¨∏ ÏûÖÎ†•Î∞õÍ∏∞
    if st.button("ÏùëÎãµ ÏÉùÏÑ±"):  # ÏùëÎãµ Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú
        if query:
            with st.spinner("AIÍ∞Ä ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ± Ï§ëÏûÖÎãàÎã§..."):
                answer = generate_response(query)  # GPT Î™®Îç∏ÏùÑ Ïù¥Ïö©Ìï¥ ÎãµÎ≥Ä ÏÉùÏÑ±
            st.subheader("GPT-3.5Ïùò ÎãµÎ≥Ä")
            st.markdown(answer, unsafe_allow_html=True)  # ÏùëÎãµ Ï∂úÎ†•

elif query_type == "ÎûúÎç§ Î¨∏Ï†ú ÌíÄÍ∏∞":
    if "current_question" not in st.session_state:
        st.session_state.current_question = None
        st.session_state.current_options = []
        st.session_state.correct_answer = None
        st.session_state.answered = False

    if st.button("ÎûúÎç§ Î¨∏Ï†ú Ï∂úÏ†ú"):  # ÎûúÎç§ Î¨∏Ï†ú Ï∂úÏ†ú Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú
        result = get_random_question_from_faiss()
        if result and all(result):  # Ïú†Ìö®Ìïú Î¨∏Ï†ú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÏúºÎ©¥
            st.session_state.current_question, st.session_state.current_options, st.session_state.correct_answer = result
            st.session_state.answered = False
    
    if st.session_state.current_question:
        st.subheader("üìñ ÎûúÎç§ Î¨∏Ï†ú")
        st.markdown(st.session_state.current_question, unsafe_allow_html=True)

        selected_option = st.radio("Ï†ïÎãµÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî:", st.session_state.current_options, index=None)  # ÏÑ†ÌÉùÏßÄ ÌëúÏãú

        if st.button("Ï†ïÎãµ ÌôïÏù∏"):  # Ï†ïÎãµ ÌôïÏù∏ Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú
            if selected_option is None:
                st.warning("‚ö†Ô∏è Ï†ïÎãµÏùÑ ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî!")
            else:
                st.session_state.answered = True
                if selected_option == st.session_state.correct_answer:
                    st.success("‚úÖ Ï†ïÎãµÏûÖÎãàÎã§!")
                else:
                    st.error(f"‚ùå Ïò§ÎãµÏûÖÎãàÎã§! Ï†ïÎãµÏùÄ: {st.session_state.correct_answer}")

        if st.session_state.answered:
            if st.button("ÏÉàÎ°úÏö¥ Î¨∏Ï†ú Ï∂úÏ†ú"):  # ÏÉàÎ°úÏö¥ Î¨∏Ï†ú Ï∂úÏ†ú Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú
                st.session_state.current_question = None
                st.session_state.current_options = []
                st.session_state.correct_answer = None
                st.session_state.answered = False
                st.rerun()  # ÌéòÏù¥ÏßÄ ÏÉàÎ°ú Í≥†Ïπ®
```
---

## üé¨ÏàòÌñâÍ≤∞Í≥º(ÌÖåÏä§Ìä∏/ÏãúÏó∞ ÌéòÏù¥ÏßÄ)

## **1. ÎπàÏπ∏ Î¨∏Ï†ú Ìï¥Í≤∞**  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/c39017ae-5cb1-4718-b53b-9f78072266b6" width="600px" height="470px">
</p>

<br>  

PDF Î≥ÄÌôò Í≥ºÏ†ïÏóêÏÑú ÎπàÏπ∏ÏùÑ Ìè¨Ìï®Ìïú ÏßÄÎ¨∏Ïù¥ ÎàÑÎùΩÎêòÎäî Î¨∏Ï†úÎ•º ÌôïÏù∏ÌïòÏòÄÏäµÎãàÎã§. Ïù¥Î°ú Ïù∏Ìï¥ Ï±óÎ¥áÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÎπàÏπ∏ Î¨∏Ï†úÎ•º Ï†úÍ≥µÌïòÏßÄ Î™ªÌïòÎäî Ïò§Î•òÍ∞Ä Î∞úÏÉùÌïòÏòÄÏäµÎãàÎã§.  

<br>  

Ïù¥Î•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥, JSON Î≥ÄÌôò ÌõÑ ÏÇ¨ÎùºÏßÑ ÎπàÏπ∏ÏùÑ `_ (underscore)` Í∏∞Ìò∏Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏßÅÏ†ë Ï∂îÍ∞ÄÌï®ÏúºÎ°úÏç® Î¨∏Ï†ú ÌòïÏãùÏùÑ Î≥¥ÏôÑÌïòÏòÄÏäµÎãàÎã§.  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/2e2d1116-64e3-4e0e-9c3b-919bede8010a" width="600px" height="470px">
</p>

<br>  

---

## **2. Î∞ëÏ§ÑÏù¥ Ìè¨Ìï®Îêú ÌÖçÏä§Ìä∏ Î¨∏Ï†ú Ìï¥Í≤∞**  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/7737df6d-8643-40fe-ba37-f571d3a8df99" width="600px" height="430px">
</p>

<br>  

PDF Î≥ÄÌôò Í≥ºÏ†ïÏóêÏÑú Î∞ëÏ§Ñ Ïπú ÌÖçÏä§Ìä∏Í∞Ä ÏÇ¨ÎùºÏßÄÎäî Î¨∏Ï†úÎ•º ÌôïÏù∏ÌïòÏòÄÏäµÎãàÎã§. Ïù¥Î°ú Ïù∏Ìï¥ ÏÑ†ÌÉùÏßÄÎÇò ÏßÄÎ¨∏ ÎÇ¥ Ï§ëÏöîÌïú Î∂ÄÎ∂ÑÏù¥ Ïú†Ïã§ÎêòÎäî ÌòÑÏÉÅÏù¥ Î∞úÏÉùÌïòÏòÄÏäµÎãàÎã§.  

<br>  

Ïù¥Î•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥, JSON ÌååÏùº ÎÇ¥ÏóêÏÑú Î∞ëÏ§ÑÏù¥ Ìè¨Ìï®Îêú ÌÖçÏä§Ìä∏ ÏñëÏ™ΩÏóê `<u>Ìï¥ÎãπÌÖçÏä§Ìä∏</u>`Î•º ÏÇΩÏûÖÌïòÏó¨ ÏõêÎ≥∏ PDF ÏÑúÏãùÏùÑ Ïú†ÏßÄÌïòÎèÑÎ°ù Ï°∞Ï†ïÌïòÏòÄÏäµÎãàÎã§.  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/d7652367-aaf7-440b-aeb3-96a4f7612bb3" width="600px" height="430px">
</p>

<br>  

---

## **3. ÎîîÎ≤ÑÍπÖ Î©îÏãúÏßÄ Ï∂úÎ†• Î¨∏Ï†ú Ìï¥Í≤∞**  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/cb1fee0a-83da-452f-9209-5b8a3f9e01f9" width="600px" height="430px">
</p>

<br>  

Ï±óÎ¥áÏùò ÏùëÎãµ Í≥ºÏ†ïÏóêÏÑú ÏùòÎèÑÏπò ÏïäÍ≤å ÎÇ¥Î∂Ä ÎîîÎ≤ÑÍπÖ Î©îÏãúÏßÄÍ∞Ä Ìï®Íªò Ï∂úÎ†•ÎêòÎäî Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌïòÏòÄÏäµÎãàÎã§. Ïù¥Î°ú Ïù∏Ìï¥ ÏÇ¨Ïö©ÏûêÍ∞Ä Î¨∏Ï†úÎ•º Ìë∏Îäî Í≥ºÏ†ïÏóêÏÑú Î∂àÌïÑÏöîÌïú DEBUG Î∞è INFO Î©îÏãúÏßÄÍ∞Ä ÎÖ∏Ï∂úÎêòÎäî ÌòÑÏÉÅÏù¥ ÌôïÏù∏ÎêòÏóàÏäµÎãàÎã§.  

<br>  

Ïù¥ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌï¥, `streamlit.py`ÏóêÏÑú Î°úÍπÖ Î†àÎ≤®ÏùÑ Ï°∞Ï†ïÌïòÏó¨ DEBUG Î∞è INFO Î©îÏãúÏßÄÍ∞Ä Ï∂úÎ†•ÎêòÏßÄ ÏïäÎèÑÎ°ù Î≥ÄÍ≤ΩÌïòÏòÄÏäµÎãàÎã§.  

<br>  

<p align="center">
  <img src="https://github.com/user-attachments/assets/5dd23d3c-7536-4851-89a5-96d6f1d1b92e" width="600px" height="550px">
</p>

<br>  


## üìå Ï∂îÍ∞Ä Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌïú ÏÇ¨Ìï≠
ÌòÑÏû¨ Ï±óÎ¥áÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÎπàÏπ∏ Î¨∏Ï†úÎ•º ÏÉùÏÑ±Ìï† Ïàò ÏûàÎèÑÎ°ù Í∞úÏÑ†ÎêòÏóàÏßÄÎßå, Î≥¥Îã§ Ìñ•ÏÉÅÎêú ÏÑ±Îä•ÏùÑ ÏúÑÌï¥ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ï∂îÍ∞Ä Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.
<br>
1. Ï±óÎ¥áÏù¥ ÏòÅÏñ¥Î°ú ÏùëÎãµÌïòÎäî Î¨∏Ï†ú: Ï±óÎ¥áÏù¥ ÌïúÍµ≠Ïñ¥Î°ú Îêú ÏßàÎ¨∏ÏùÑ Î∞õÏïòÏùåÏóêÎèÑ ÏùºÎ∂Ä ÏùëÎãµÏù¥ ÏòÅÏñ¥Î°ú Ï∂úÎ†•ÎêòÎäî ÌòÑÏÉÅÏù¥ Î∞úÏÉùÌï©ÎãàÎã§.
2. ÏßÄÏãúÎ¨∏, ÏßÄÎ¨∏, ÏÑ†ÌÉùÏßÄ Ï§ë ÏùºÎ∂ÄÍ∞Ä ÎàÑÎùΩÎêòÎäî Î¨∏Ï†ú: JSON Î≥ÄÌôò Í≥ºÏ†ïÏóêÏÑú ÌäπÏ†ï ÏöîÏÜå(ÏßÄÏãúÎ¨∏, ÏßÄÎ¨∏, ÏÑ†ÌÉùÏßÄ)Ïùò ÏùºÎ∂ÄÍ∞Ä Ï†ïÏÉÅÏ†ÅÏúºÎ°ú Î≥ÄÌôòÎêòÏßÄ ÏïäÎäî Í≤ΩÏö∞Í∞Ä Í¥ÄÏ∞∞ÎêòÏóàÏäµÎãàÎã§.
3. Í∑∏Î¶ºÏù¥ÎÇò Í∑∏ÎûòÌîÑ Ìè¨Ìï® Î¨∏Ï†ú: PDFÏóê Ìè¨Ìï®Îêú Í∑∏Î¶º, Ìëú, Í∑∏ÎûòÌîÑ Îì±Ïùò ÏöîÏÜåÍ∞Ä ÌÖçÏä§Ìä∏ Î≥ÄÌôò Í≥ºÏ†ïÏóêÏÑú ÎàÑÎùΩÎêòÍ±∞ÎÇò ÏôúÍ≥°ÎêòÎäî Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌï©ÎãàÎã§.

---
 
## üí≠Ìïú Ï§Ñ ÌöåÍ≥†

ÏÑúÏ£ºÌòÅ: OpenAIÏùò text-embedding-ada-002 Î™®Îç∏ÏùÑ ÌôúÏö©ÌïòÎ©∞, ÏµúÏã† ÏûÑÎ≤†Îî© Í∏∞Ïà†Ïùò ÏÑ±Îä•Í≥º ÌïúÍ≥ÑÎ•º Ï≤¥Í∞êÌïú ÌîÑÎ°úÏ†ùÌä∏ÏòÄÎã§.
<br>
ÎåÄÏÑ±Ïõê: Îç∞Ïù¥ÌÑ∞Î•º Ïò®Ï†ÑÌûà Ï≤òÎ¶¨ÌïòÍ≥† ÏõêÌïòÎäî Í≤∞Í¥èÍ∞íÏùÑ ÎèÑÏ∂úÌï¥ÎÇ¥Í∏∞ ÏúÑÌï¥ÏÑúÎäî ÏÉùÍ∞ÅÎ≥¥Îã§ Î≥µÏû°Ìïú ÏàòÏûëÏóÖÏù¥ ÌïÑÏöîÌï† Ïàò ÏûàÎã§Îäî Í≤ÉÏùÑ Íπ®Îã¨ÏïòÎã§.
<br>
Ïú§Ï†ïÏó∞: Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÎ©¥ÏÑú Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Í≥ºÏ†ïÏù¥ ÏñºÎßàÎÇò Ï§ëÏöîÌïúÏßÄ, Í∑∏Î¶¨Í≥† ÏÑ∏Ïã¨Ìïú Ï°∞Ï†ïÏù¥ Í≤∞Í≥ºÏóê ÌÅ∞ ÏòÅÌñ•ÏùÑ ÎØ∏Ïπ† Ïàò ÏûàÎã§Îäî Í≤ÉÏùÑ Íπ®Îã¨ÏïòÎã§.
